{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPSS Decision Tree with Visualization\n",
    "\n",
    "First we need to import the necessary libraries for the decision tree, model viewer, and Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import com.ibm.spss.ml.classificationandregression.tree.CHAID\n",
    "import com.ibm.spss.scala.ModelViewer\n",
    "import org.apache.spark.sql.SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a sqlContext that will allow us to talk to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val sqlContext = new SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will be used to read our CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setHadoopConfig(credentials: collection.mutable.Map[String, String]) = {\n",
    "    val prefix = \"fs.swift.service.\" + credentials(\"name\") \n",
    "    val hconf = sc.hadoopConfiguration\n",
    "    hconf.set(prefix + \".auth.url\", credentials(\"auth_url\") + \"/v3/auth/tokens\")\n",
    "    hconf.set(prefix + \".auth.endpoint.prefix\", \"endpoints\")\n",
    "    hconf.set(prefix + \".tenant\", credentials(\"project_id\"))\n",
    "    hconf.set(prefix + \".username\", credentials(\"user_id\"))\n",
    "    hconf.set(prefix + \".password\", credentials(\"password\"))\n",
    "    hconf.setInt(prefix + \".http.port\", 8080)\n",
    "    hconf.set(prefix + \".region\", credentials(\"region\"))\n",
    "    hconf.setBoolean(prefix + \".public\", true)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To import data \n",
    "- Click on the cell below this.\n",
    "- Click the 1010 icon on the top right\n",
    "- Click on \"Insert to Code\" under transactions.csv\n",
    "- rename \"var credentials_...\" in the first line to be \"var credentials\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials(\"name\") = \"chaid\"\n",
    "setHadoopConfig(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val filePath = \"swift://\" + credentials(\"container\") + \".\" + credentials(\"name\") + \"/\"\n",
    "val fileName = credentials(\"filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a Spark SQL dataframe from the transactions.csv data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val df = sqlContext.read.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").option(\"inferschema\", \"true\").load(filePath + fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many records in data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60252"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any nulls? No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60252"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.na.drop.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+-----------------+---------------+-----+--------------+------+---+--------------+------------+\n",
      "|        PRODUCT_LINE|PRODUCT_TYPE|CUST_ORDER_NUMBER|           CITY|STATE|       COUNTRY|GENDER|AGE|MARITAL_STATUS|  PROFESSION|\n",
      "+--------------------+------------+-----------------+---------------+-----+--------------+------+---+--------------+------------+\n",
      "|Personal Accessories|  Navigation|           174344|       Plymouth|   NA|United Kingdom|     M| 27|        Single|Professional|\n",
      "|Personal Accessories|     Eyewear|           170637|        Leipzig|   NA|       Germany|     F| 39|       Married|       Other|\n",
      "|Mountaineering Eq...|        Rope|           170637|        Leipzig|   NA|       Germany|     F| 39|       Married|       Other|\n",
      "|Personal Accessories|  Binoculars|           170641|         Manaus|BR-AM|        Brazil|     F| 56|   Unspecified| Hospitality|\n",
      "|      Golf Equipment|       Woods|           170643|College Station|   TX| United States|     M| 45|       Married|     Retired|\n",
      "+--------------------+------------+-----------------+---------------+-----+--------------+------+---+--------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PRODUCT_LINE: string (nullable = true)\n",
      " |-- PRODUCT_TYPE: string (nullable = true)\n",
      " |-- CUST_ORDER_NUMBER: integer (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- COUNTRY: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to bin Age in order to use in the Chaid decision tree.  We will leave this out for now.  Try coding this up as a challenge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|               AGE|\n",
      "+-------+------------------+\n",
      "|  count|             60252|\n",
      "|   mean|  34.1874792538007|\n",
      "| stddev|10.105477019283859|\n",
      "|    min|                17|\n",
      "|    max|                69|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe(\"AGE\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split our data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val Array(training, test) = df.randomSplit(Array(0.6, 0.4), seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we choose our model and set the target and predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val chaid = CHAID().setTargetField(\"PRODUCT_LINE\").setInputFieldList(Array(\"GENDER\", \"PROFESSION\", \"MARITAL_STATUS\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val chaidModel = chaid.fit(training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Visualization\n",
    "\n",
    "This output shows a single output that contains everything you need to evaluate your model.  This output contains 3 tables and 2 interactive charts.  Although for this model the Predictor Importance is constant so that chart was not drawn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel.magics.html(ModelViewer.toHTML(chaidModel))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10 with Spark 1.6",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}